'''
è®­ç»ƒRNNæ¨¡å‹ä½¿å¾—  "hello" -> "ohlol"
è¾“å…¥ä¸º"hello"ï¼Œå¯è®¾ç½®å­—å…¸ e -> 0 h -> 1 l -> 2 o -> 3 helloå¯¹åº”ä¸º 10223 one-hotç¼–ç æœ‰ä¸‹é¢å¯¹åº”å…³ç³»
h   1   0100            o   3
e   0   1000            h   1
l   2   0010            l   2
l   2   0010            o   3
o   3   0001            l   2
è¾“å…¥æœ‰â€œheloâ€å››ä¸ªä¸åŒç‰¹å¾äºæ˜¯input_size = 4
hidden_size = 4(è‡ªå·±è®¾å®šçš„) batch_size = 1 ä¸€æ¬¡å‰å‘åå‘ä¸­è®­ç»ƒæ ·æœ¬çš„ä¸ªæ•°

RNNæ¨¡å‹ç»´åº¦çš„ç¡®è®¤è‡³å…³é‡è¦ï¼š
rnn = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size,num_layers=num_layers)
outputs, hidden_outs = rnn(inputs, hiddens):
    inputs of shape ğ‘ ğ‘’ğ‘ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘ğ‘ğ‘¡ğ‘â„, ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’
    hiddens of shape ğ‘›ğ‘¢ğ‘šğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿğ‘ , ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
    outputs of shape ğ‘ ğ‘’ğ‘ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
    hidden_outs of shape ğ‘ ğ‘’ğ‘ğ‘†ğ‘–ğ‘§ğ‘’, ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
cell = torch.nn.RNNcell(input_size=input_size, hidden_size=hidden_size)
output, hidden_out = cell(input, hidden):
    input of shape ğ‘ğ‘ğ‘¡ğ‘â„, ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’
    hidden of shape ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
    output of shape ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
    hidden_out of shape ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
å…¶ä¸­ï¼ŒseqSizeï¼šè¾“å…¥ä¸ªæ•°  batchï¼šæ‰¹é‡å¤§å°  input_sizeï¼šç‰¹å¾ç»´æ•° numLayersï¼šç½‘ç»œå±‚æ•°  hidden_sizeï¼šéšè—å±‚ç»´æ•°
'''
import torch

idx2char = ['e', 'h', 'l', 'o'] #æ–¹ä¾¿æœ€åè¾“å‡ºç»“æœ
x_data = [1, 0, 2, 2, 3]        #è¾“å…¥å‘é‡
y_data = [3, 1, 2, 3, 2]        #æ ‡ç­¾

one_hot_lookup = [ [1, 0, 0, 0], #æŸ¥è¯¢ont hotç¼–ç  æ–¹ä¾¿è½¬æ¢
                   [0, 1, 0, 0],
                   [0, 0, 1, 0],
                   [0, 0, 0, 1] ]
x_one_hot = [one_hot_lookup[x] for x in x_data] #æŒ‰"1 0 2 2 3"é¡ºåºå–one_hot_lookupä¸­çš„å€¼èµ‹ç»™x_one_hotï¼Œç»´åº¦(seqLen,inputSize)
#åˆ—è¡¨ç”Ÿæˆå¼
'''è¿è¡Œç»“æœä¸ºx_one_hot = [ [0, 1, 0, 0],
                          [1, 0, 0, 0],
                          [0, 0, 1, 0],
                          [0, 0, 1, 0],
                          [0, 0, 0, 1] ]
åˆšå¥½å¯¹åº”è¾“å…¥å‘é‡ï¼Œä¹Ÿå¯¹åº”ç€å­—ç¬¦å€¼'hello'
'''

input_size = 4
hidden_size = 4
batch_size = 1
inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)
#reshape the inputs to (seqLen,batchSize,inputSize)ï¼Œ-1è¡¨ç¤ºè‡ªåŠ¨é€‚é…ï¼ˆè‡ªåŠ¨åˆ¤æ–­ç»´åº¦ï¼‰
labels = torch.LongTensor(y_data).view(-1, 1)#å¢åŠ ç»´åº¦æ–¹ä¾¿è®¡ç®—loss

class cell_Model(torch.nn.Module):
    def __init__(self,input_size, hidden_size, batch_size):
        super(cell_Model, self).__init__()
        self.input_size = input_size
        self.batch_size = batch_size
        self.hidden_size = hidden_size
        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)

    def forward(self, input, hidden):
        hidden = self.rnncell(input, hidden)#shape: ğ‘ğ‘ğ‘¡ğ‘â„, ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’
        return hidden

    def init_hidden(self):
        return torch.zeros(self.batch_size, self.hidden_size)#æä¾›åˆå§‹åŒ–éšè—å±‚ï¼ˆh0ï¼‰

net = cell_Model(input_size, hidden_size, batch_size) #batchSizeåªæœ‰åœ¨æ„é€ h0æ—¶æ‰ä¼šç”¨åˆ°

#---è®¡ç®—æŸå¤±å’Œæ›´æ–°
criterion = torch.nn.CrossEntropyLoss()#äº¤å‰ç†µ
optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)
#---è®¡ç®—æŸå¤±å’Œæ›´æ–°

for epoch in range(50):#è®­ç»ƒ50æ¬¡
    loss = 0
    optimizer.zero_grad() #æ¯è½®è®­ç»ƒä¹‹å‰å…ˆå°†ä¼˜åŒ–å™¨æ¢¯åº¦å½’é›¶
    hidden = net.init_hidden()
    print('Predicten string:', end='')
    for input, label in zip(inputs,labels):#å¹¶è¡Œéå†æ•°æ®é›† ä¸€ä¸ªä¸€ä¸ªè®­ç»ƒ
        #inputsç»´åº¦æ˜¯(seqLen,batchSize,inputSize)ï¼Œzipæ˜¯æ²¿ç¬¬ä¸€ä¸ªç»´åº¦æ‹¼æ¥ï¼Œä¸€ä¸ªåºåˆ—å¯¹åº”ä¸€ä¸ªlabel
        hidden = net(input, hidden)#shape: ğ‘ğ‘ğ‘¡ğ‘â„, ğ‘–ğ‘›ğ‘ğ‘¢ğ‘¡_ğ‘ ğ‘–ğ‘§ğ‘’        ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
        #hiddenè¾“å‡ºç»´åº¦ ğ‘ğ‘ğ‘¡ğ‘â„, â„ğ‘–ğ‘‘ğ‘‘ğ‘’ğ‘›_ğ‘ ğ‘–ğ‘§ğ‘’
        loss += criterion(hidden, label) #æ­¤å¤„éœ€è¦æ„é€ è®¡ç®—å›¾ï¼Œå¯¹åºåˆ—æ•´ä¸ªçš„æŸå¤±æ±‚å’Œï¼Œæ‰€ä»¥ä¸è¦ç”¨Item()
        _, idx = hidden.max(dim=1)#ä»ç¬¬ä¸€ä¸ªç»´åº¦ä¸Šå–å‡ºé¢„æµ‹æ¦‚ç‡æœ€å¤§çš„å€¼å’Œè¯¥å€¼æ‰€åœ¨åºå·ï¼Œå³ä»e,h,l,oä¸­æŒ‘å‡ºæœ€å¯èƒ½è¾“å‡ºçš„å­—æ¯ï¼Œå‚è§L9
        print(idx2char[idx.item()], end='')#æŒ‰ä¸Šé¢åºå·è¾“å‡ºç›¸åº”å­—æ¯å­—ç¬¦
    loss.backward()
    optimizer.step()
    print(', Epoch [%d/50] loss=%.4f' %(epoch+1, loss.item()))
